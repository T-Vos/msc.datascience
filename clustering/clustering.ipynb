{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../EDA/data.csv')\n",
    "Y = pd.read_csv('../EDA/y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_without = dataset.drop(columns=[\"year\",\"country\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.merge(Y, how='left', on=[\"year\",\"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_without = X_without.fillna(0)\n",
    "X_without = X_without.replace(np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thoma\\.conda\\envs\\thesisProject\\lib\\site-packages\\pandas\\core\\series.py:726: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Thoma\\.conda\\envs\\thesisProject\\lib\\site-packages\\pandas\\core\\series.py:726: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "bigNumbers = X_without.max()[X_without.max() > 10000000].keys()\n",
    "for bigColumn in bigNumbers:\n",
    "    X_without[bigColumn+\"log\"] = np.log10(X_without[bigColumn])\n",
    "\n",
    "# X_without = X_without.drop(columns=bigNumbers, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_without = X_without.replace(np.inf, 0)\n",
    "X_without = X_without.replace(-np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e2576b1b40e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprincipalComponents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thoma\\.conda\\envs\\thesisProject\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \"\"\"\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thoma\\.conda\\envs\\thesisProject\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[0m\u001b[0;32m    398\u001b[0m                                 ensure_2d=True, copy=self.copy)\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thoma\\.conda\\envs\\thesisProject\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thoma\\.conda\\envs\\thesisProject\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thoma\\.conda\\envs\\thesisProject\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thoma\\.conda\\envs\\thesisProject\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = StandardScaler().fit_transform(X_without)\n",
    "\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "features = range(1,23)\n",
    "plt.bar(features, pca.explained_variance_ratio_[:22], color='black')\n",
    "plt.xlabel('PCA features')\n",
    "plt.ylabel('variance %')\n",
    "plt.xticks(features)\n",
    "plt.figure(figsize=(20, 2))\n",
    "\n",
    "PCA_components = pd.DataFrame(principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pca.explained_variance_ratio_[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tSNE = TSNE(n_components=3)\n",
    "tSNE_COMPS = tSNE.fit_transform(PCA_components)\n",
    "\n",
    "tSNE_PCA_components = pd.DataFrame(tSNE_COMPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tSNE_PCA_components[0], tSNE_PCA_components[1], alpha=.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(PCA_components[0], PCA_components[1], PCA_components[3], alpha=.5)\n",
    "ax.view_init(elev=5., azim=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "components = 15\n",
    "features = 11\n",
    "\n",
    "gmm = mixture.GaussianMixture(n_components=components, covariance_type='full')\n",
    "labels = gmm.fit_predict(PCA_components.iloc[:,:features])\n",
    "\n",
    "X_without[\"gmmLabels-\"+str(components)+str(features)] = labels\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(PCA_components[0], PCA_components[1], PCA_components[3], c=labels, alpha=.5)\n",
    "ax.view_init(elev=5., azim=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(PCA_components[0], PCA_components[2], PCA_components[4], c=labels, alpha=.5)\n",
    "ax.view_init(elev=5., azim=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower\n",
    "results = dict()\n",
    "k_cand = list(np.arange(5,55,5))\n",
    "k_cand.extend(list(np.arange(50,500,50)))\n",
    "\n",
    "gd = gower.gower_matrix(tSNE_PCA_components.iloc[:,:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = shc.linkage(tSNE_PCA_components, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import gower\n",
    "from sklearn.metrics import  silhouette_score\n",
    "\n",
    "results = dict()\n",
    "k_cand = list(np.arange(5,20,1))\n",
    "# k_cand.extend(list(np.arange(50,1000,50)))\n",
    "\n",
    "for features in range(1,12):\n",
    "    gd = gower.gower_matrix(PCA_components.iloc[:,:features])\n",
    "    cluster = shc.linkage(PCA_components.iloc[:,:features], method='complete')\n",
    "\n",
    "    for k in k_cand:\n",
    "        cluster_array = fcluster(cluster, k, criterion='maxclust')\n",
    "        score0 = silhouette_score(gd, cluster_array, metric='precomputed')\n",
    "        score1 = silhouette_score(PCA_components.iloc[:,:features], cluster_array,metric='cityblock')\n",
    "        results[k] = {'k':cluster_array,'s0':score0,'s1':score1}\n",
    "        \n",
    "    fig,axs = plt.subplots(1,1,figsize=(16,5))\n",
    "    axs.plot([i for i in results.keys()],[i['s0'] for i in results.values()],'o-',label='Gower')\n",
    "    axs.plot([i for i in results.keys()],[i['s1'] for i in results.values()],'o-',label='Cityblock')\n",
    "    # axs.set_xlim(1,451)\n",
    "    axs.set_xticks(k_cand)\n",
    "    axs.set_xlabel('K')\n",
    "    axs.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import mixture\n",
    "from sklearn.metrics import  silhouette_score\n",
    "\n",
    "k_cand = list(np.arange(2,20,1))\n",
    "features = 11\n",
    "results = dict()\n",
    "\n",
    "for k in k_cand:\n",
    "\n",
    "    kmeans = KMeans( n_clusters=k)\n",
    "    labels = kmeans.fit_predict(PCA_components.iloc[:,:features])\n",
    "    score0 = kmeans.inertia_\n",
    "    score1 = silhouette_score(PCA_components.iloc[:,:features],labels,metric='euclidean')\n",
    "    score2 = silhouette_score(PCA_components.iloc[:,:features],labels,metric='correlation')\n",
    "    score3 = silhouette_score(PCA_components.iloc[:,:features],labels,metric='manhattan')\n",
    "    results[k] = {'k':kmeans,'s0':score0,'s1':score1,'s2':score2,'s3':score3}\n",
    "\n",
    "fig,axs = plt.subplots(2,1,sharex=True,figsize=(16,8))\n",
    "plt.title('features '+ str(features))\n",
    "axs[0].plot([i for i in results.keys()],[i['s0'] for i in results.values()],'o-',label='intertia')\n",
    "axs[1].plot([i for i in results.keys()],[i['s1'] for i in results.values()],'o-',label='Euclidean')\n",
    "axs[1].plot([i for i in results.keys()],[i['s2'] for i in results.values()],'o-',label='Correlation')\n",
    "axs[1].plot([i for i in results.keys()],[i['s3'] for i in results.values()],'o-',label='Manhattan')\n",
    "for ax in axs:\n",
    "    ax.set_xticks(k_cand)\n",
    "    ax.set_xlabel('K')\n",
    "    ax.legend()\n",
    "\n",
    "plt.savefig(\"features-minmax-scale\"+str(features)+\".png\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn import mixture\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "features = 6\n",
    "range_n_clusters = range(2,10)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(PCA_components.iloc[:,:features]) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = mixture.GaussianMixture(n_components=n_clusters)\n",
    "    cluster_labels = clusterer.fit_predict(PCA_components.iloc[:,:features])\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(PCA_components.iloc[:,:features], cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        n_clusters,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(PCA_components.iloc[:,:features], cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(\n",
    "        PCA_components.iloc[:, 0], PCA_components.iloc[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    # # Labeling the clusters\n",
    "    # centers = clusterer.cluster_centers_\n",
    "    # # Draw white circles at cluster centers\n",
    "    # ax2.scatter(\n",
    "    #     centers[:, 0],\n",
    "    #     centers[:, 1],\n",
    "    #     marker=\"o\",\n",
    "    #     c=\"white\",\n",
    "    #     alpha=1,\n",
    "    #     s=200,\n",
    "    #     edgecolor=\"k\",\n",
    "    # )\n",
    "\n",
    "    # for i, c in enumerate(centers):\n",
    "    #     ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % n_clusters,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "\n",
    "\n",
    "for features in range(1,20):\n",
    "    lowest_bic = np.infty\n",
    "    bic = []\n",
    "    n_components_range = list(np.arange(1, 20,1))\n",
    "    n_components_range.extend(list(np.arange(50,500,50)))\n",
    "    cv_types = [\"spherical\", \"tied\", \"diag\", \"full\"]\n",
    "    for cv_type in cv_types:\n",
    "        for n_components in n_components_range:\n",
    "            # Fit a Gaussian mixture with EM\n",
    "            gmm = mixture.GaussianMixture(\n",
    "                n_components=n_components, covariance_type=cv_type\n",
    "            )\n",
    "            gmm.fit(PCA_components.iloc[:,:features])\n",
    "            bic.append(gmm.bic(PCA_components.iloc[:,:features]))\n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "\n",
    "    bic = np.array(bic)\n",
    "    color_iter = itertools.cycle([\"navy\", \"turquoise\", \"cornflowerblue\", \"darkorange\"])\n",
    "    clf = best_gmm\n",
    "    bars = []\n",
    "\n",
    "    # Plot the BIC scores\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    spl = plt.subplot(1, 1, 1)\n",
    "    for i, (cv_type, color) in enumerate(zip(cv_types, color_iter)):\n",
    "        xpos = np.array(n_components_range) + 0.2 * (i - 2)\n",
    "        bars.append(\n",
    "            plt.bar(\n",
    "                xpos,\n",
    "                bic[i * len(n_components_range) : (i + 1) * len(n_components_range)],\n",
    "                width=0.2,\n",
    "                color=color,\n",
    "            )\n",
    "        )\n",
    "    plt.xticks(n_components_range)\n",
    "    plt.ylim([bic.min() * 1.01 - 0.01 * bic.max(), bic.max()])\n",
    "    plt.title(\"BIC score per model \" +str(features))\n",
    "    xpos = (\n",
    "        np.mod(bic.argmin(), len(n_components_range))\n",
    "        + 0.65\n",
    "        + 0.2 * np.floor(bic.argmin() / len(n_components_range))\n",
    "    )\n",
    "    plt.text(xpos, bic.min() * 0.97 + 0.03 * bic.max(), \"*\", fontsize=14)\n",
    "    spl.set_xlabel(\"Number of components\")\n",
    "    spl.legend([b[0] for b in bars], cv_types)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkingMatrix = X_without.iloc[:,-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as scStat\n",
    "\n",
    "setToCompare = \"gmmLabels-84\"\n",
    "clusters = len(checkingMatrix[setToCompare].unique())\n",
    "democracyScore = \"v2x_libdem\"\n",
    "\n",
    "clusters = len(checkingMatrix[setToCompare].unique())\n",
    "\n",
    "bars = [np.mean(checkingMatrix[checkingMatrix[setToCompare]==i][democracyScore].dropna().values) for i in range(clusters)]\n",
    "plt.bar(range(clusters),bars)\n",
    "plt.xticks(range(clusters))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# zeroArray = np.zeros((clusters+1,clusters+1))\n",
    "zeroArray = [[0]*(clusters+1)]*(clusters+1)\n",
    "\n",
    "barlett = [checkingMatrix[checkingMatrix[setToCompare]==i][democracyScore].dropna().values for i in range(clusters)]\n",
    "barlettTest = scStat.levene(*barlett)\n",
    "\n",
    "print(barlettTest)\n",
    "\n",
    "for i in range(clusters):\n",
    "    # print(len(checkingMatrix[checkingMatrix[setToCompare]==i][\"v2x_partipdem\"]))\n",
    "    compareSet = checkingMatrix[checkingMatrix[setToCompare]==i][democracyScore].dropna().values\n",
    "    if len(compareSet) > 8:\n",
    "        normality_v2X_PartiDem = scStat.normaltest(compareSet)\n",
    "        print(normality_v2X_PartiDem, barlettTest)\n",
    "        for z in range(clusters):\n",
    "            tTest = 0\n",
    "            if i != z:\n",
    "                compareSet2 = checkingMatrix[checkingMatrix[setToCompare]==z][democracyScore].dropna().values\n",
    "                levene = scStat.levene(compareSet,compareSet2)\n",
    "                print(levene)\n",
    "\n",
    "                if len(compareSet2) > 8:\n",
    "                    tTest = scStat.ttest_ind(compareSet,compareSet2)\n",
    "                    zeroArray[i][z] = (tTest[1], levene[1])\n",
    "                    print(\"Compare \"+ democracyScore +\", of cluster\", i, \" against:\", z, \":\", tTest)\n",
    "                    print(\"\")\n",
    "            else:\n",
    "                zeroArray[i][z] = 1\n",
    "    print(\"\")\n",
    "\n",
    "zeroArray"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6744874b6b7d4c11632f5c57904f17b16032f5dfc2e35ec68085b9c698263a2f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('thesisProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
